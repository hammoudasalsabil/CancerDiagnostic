{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description     : Simple Python implementation of the Apriori Algorithm\n",
    "\n",
    "Usage:\n",
    "    $python apriori.py -f DATASET.csv -s minSupport  -c minConfidence\n",
    "\n",
    "    $python apriori.py -f DATASET.csv -s 0.15 -c 0.6\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "from itertools import chain, combinations\n",
    "from collections import defaultdict\n",
    "from optparse import OptionParser\n",
    "\n",
    "\n",
    "def subsets(arr):\n",
    "    \"\"\" Returns non empty subsets of arr\"\"\"\n",
    "    return chain(*[combinations(arr, i + 1) for i, a in enumerate(arr)])\n",
    "\n",
    "\n",
    "def returnItemsWithMinSupport(itemSet, transactionList, minSupport, freqSet):\n",
    "    \"\"\"calculates the support for items in the itemSet and returns a subset\n",
    "    of the itemSet each of whose elements satisfies the minimum support\"\"\"\n",
    "    _itemSet = set()\n",
    "    localSet = defaultdict(int)\n",
    "\n",
    "    for item in itemSet:\n",
    "        for transaction in transactionList:\n",
    "            if item.issubset(transaction):\n",
    "                freqSet[item] += 1\n",
    "                localSet[item] += 1\n",
    "\n",
    "    for item, count in localSet.items():\n",
    "        support = float(count) / len(transactionList)\n",
    "\n",
    "        if support >= minSupport:\n",
    "            _itemSet.add(item)\n",
    "\n",
    "    return _itemSet\n",
    "\n",
    "\n",
    "def joinSet(itemSet, length):\n",
    "    \"\"\"Join a set with itself and returns the n-element itemsets\"\"\"\n",
    "    return set(\n",
    "        [i.union(j) for i in itemSet for j in itemSet if len(i.union(j)) == length]\n",
    "    )\n",
    "\n",
    "\n",
    "def getItemSetTransactionList(data_iterator):\n",
    "    transactionList = list()\n",
    "    itemSet = set()\n",
    "    for record in data_iterator:\n",
    "        transaction = frozenset(record)\n",
    "        transactionList.append(transaction)\n",
    "        for item in transaction:\n",
    "            itemSet.add(frozenset([item]))  # Generate 1-itemSets\n",
    "    return itemSet, transactionList\n",
    "\n",
    "\n",
    "def runApriori(data_iter, minSupport, minConfidence):\n",
    "    \"\"\"\n",
    "    run the apriori algorithm. data_iter is a record iterator\n",
    "    Return both:\n",
    "     - items (tuple, support)\n",
    "     - rules ((pretuple, posttuple), confidence)\n",
    "    \"\"\"\n",
    "    itemSet, transactionList = getItemSetTransactionList(data_iter)\n",
    "\n",
    "    freqSet = defaultdict(int)\n",
    "    largeSet = dict()\n",
    "    # Global dictionary which stores (key=n-itemSets,value=support)\n",
    "    # which satisfy minSupport\n",
    "\n",
    "    assocRules = dict()\n",
    "    # Dictionary which stores Association Rules\n",
    "\n",
    "    oneCSet = returnItemsWithMinSupport(itemSet, transactionList, minSupport, freqSet)\n",
    "\n",
    "    currentLSet = oneCSet\n",
    "    k = 2\n",
    "    while currentLSet != set([]):\n",
    "        largeSet[k - 1] = currentLSet\n",
    "        currentLSet = joinSet(currentLSet, k)\n",
    "        currentCSet = returnItemsWithMinSupport(\n",
    "            currentLSet, transactionList, minSupport, freqSet\n",
    "        )\n",
    "        currentLSet = currentCSet\n",
    "        k = k + 1\n",
    "\n",
    "    def getSupport(item):\n",
    "        \"\"\"local function which Returns the support of an item\"\"\"\n",
    "        return float(freqSet[item]) / len(transactionList)\n",
    "\n",
    "    toRetItems = []\n",
    "    for key, value in largeSet.items():\n",
    "        toRetItems.extend([(tuple(item), getSupport(item)) for item in value])\n",
    "\n",
    "    toRetRules = []\n",
    "    for key, value in list(largeSet.items())[1:]:\n",
    "        for item in value:\n",
    "            _subsets = map(frozenset, [x for x in subsets(item)])\n",
    "            for element in _subsets:\n",
    "                remain = item.difference(element)\n",
    "                if len(remain) > 0:\n",
    "                    confidence = getSupport(item) / getSupport(element)\n",
    "                    if confidence >= minConfidence:\n",
    "                        toRetRules.append(((tuple(element), tuple(remain)), confidence))\n",
    "    return toRetItems, toRetRules\n",
    "\n",
    "\n",
    "def printResults(items, rules):\n",
    "    \"\"\"prints the generated itemsets sorted by support and the confidence rules sorted by confidence\"\"\"\n",
    "    for item, support in sorted(items, key=lambda x: x[1]):\n",
    "        print(\"item: %s , %.3f\" % (str(item), support))\n",
    "    print(\"\\n------------------------ RULES:\")\n",
    "    for rule, confidence in sorted(rules, key=lambda x: x[1]):\n",
    "        pre, post = rule\n",
    "        if post[0] == 'probability' or post[0] == 'no probability' :\n",
    "        \n",
    "            print(\"Rule: %s ==> %s , %.3f\" % (str(pre), str(post), confidence))\n",
    "\n",
    "\n",
    "def to_str_results(items, rules):\n",
    "    \"\"\"prints the generated itemsets sorted by support and the confidence rules sorted by confidence\"\"\"\n",
    "    i, r = [], []\n",
    "    for item, support in sorted(items, key=lambda x: x[1]):\n",
    "        x = \"item: %s , %.3f\" % (str(item), support)\n",
    "        i.append(x)\n",
    "\n",
    "    for rule, confidence in sorted(rules, key=lambda x: x[1]):\n",
    "        pre, post = rule\n",
    "        if str(post) == 'probability':\n",
    "            x = \"Rule: %s ==> %s , %.3f\" % (str(pre), str(post), confidence)\n",
    "            r.append(x)\n",
    "\n",
    "    return i, r\n",
    "\n",
    "\n",
    "def dataFromFile(fname):\n",
    "    \"\"\"Function which reads from the file and yields a generator\"\"\"\n",
    "    with open(fname, \"rU\") as file_iter:\n",
    "        for line in file_iter:\n",
    "            line = line.strip().rstrip(\",\")  # Remove trailing comma\n",
    "            record = frozenset(line.split(\",\"))\n",
    "            yield record\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    optparser = OptionParser()\n",
    "    optparser.add_option(\n",
    "        \"-f\", \"--inputFile\", dest=\"input\", help=\"filename containing csv\", default=None\n",
    "    )\n",
    "    optparser.add_option(\n",
    "        \"-s\",\n",
    "        \"--minSupport\",\n",
    "        dest=\"minS\",\n",
    "        help=\"minimum support value\",\n",
    "        default=0.15,\n",
    "        type=\"float\",\n",
    "    )\n",
    "    optparser.add_option(\n",
    "        \"-c\",\n",
    "        \"--minConfidence\",\n",
    "        dest=\"minC\",\n",
    "        help=\"minimum confidence value\",\n",
    "        default=0.6,\n",
    "        type=\"float\",\n",
    "    )\n",
    "\n",
    "    (options, args) = optparser.parse_args()\n",
    "\n",
    "    inFile = None\n",
    "    if options.input is None:\n",
    "        inFile = sys.stdin\n",
    "    elif options.input is not None:\n",
    "        inFile = dataFromFile(options.input)\n",
    "    else:\n",
    "        print(\"No dataset filename specified, system with exit\\n\")\n",
    "        sys.exit(\"System will exit\")\n",
    "\n",
    "    minSupport = options.minS\n",
    "    minConfidence = options.minC\n",
    "\n",
    "    items, rules = runApriori(inFile, minSupport, minConfidence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(640x480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "apriori.py:143: DeprecationWarning: 'U' mode is deprecated\n",
      "  with open(fname, \"rU\") as file_iter:\n"
     ]
    }
   ],
   "source": [
    "!python apriori.py -f New_Diagnostic_Brain.csv -s 0.15 -c 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-43-c305307b7468>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-43-c305307b7468>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    plt.xlabel('support')\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "plt.scatter(0.15, 0.6, alpha=0.5, marker=\"*\")\n",
    "plt.xlabel('support') \n",
    "plt.ylabel('confidence') \n",
    "plt.title('Support vs Confidence') \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0.1 \n",
    "    for i in range(9):  \n",
    "        items, rules = runApriori(\"New_Diagnostic_Brain.csv\", 0.05, a) \n",
    "        plt.scatter(rules['support'], rules['confidence'], alpha=0.5 ,marker=\"*\") \n",
    "        plt.xlabel('support') \n",
    "        plt.ylabel('confidence') \n",
    "        plt.title('Support vs Confidence') \n",
    "        plt.show() \n",
    "        a= a + 0.1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
